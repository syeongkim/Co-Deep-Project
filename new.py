# -*- coding: utf-8 -*-
"""new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Us7iNvRXH7BeAGXbpXk6pasB1jpHNtOs
"""

#드라이브에 접근할 수 있도록 아래 코드 입력
from google.colab import drive
drive.mount('/content/drive')

# 구글 스트리트뷰를 설치한다
!pip install google_streetview
import google_streetview.api
import google_streetview.helpers

file = open('test_non_criminal.txt', 'r')
s=file.read()

# Create a dictionary with multiple parameters separated by ;
apiargs = {
  'location': s,
  'size': '640x640',
  'heading': '270;0;90;180', # 270도, 0도, 90도, 180도 회전으로 카메라를 한 시점에서 90도씩 돌린 사진들을 받아온다.
  'fov': '90', # 시야각은 90도로 제한한다.
  'pitch': '0',
  'key':'AIzaSyAY1YUMuoVeeaHbywwuIaPM4B92zydNsaA'
}

# 다수의 파라미터들로부터 가능한 쿼리들의 리스트를 받아온다.
api_list = google_streetview.helpers.api_list(apiargs)

# 가능한 결과 객체들을 모두 생성한다. 
results = google_streetview.api.results(api_list)

# 미리보기
results.preview()

# 디렉토리에 결과들을 다운로드한다.
results.download_links('/content/drive/MyDrive/Colab Notebooks/test_image_data_nc')

# 메타데이터를 저장한다. 
results.save_metadata('metadata.json')

file.close()

from PIL import Image
# pillow 데이터
finalcount = 1
count = 0

for i in range(7000): # 받아온 사진 데이터들의 개수 - 마지막이 아니면 7000개로 고정한다.
    
    # 이미지는 gsv에서 한 번에 다운받을 경우 gsv_n 형태로 동일하게 다운받아진다.
    # 이미지의 이름을 저장해 준다.
    image1 = "drive/MyDrive/Colab Notebooks/test_image_data_nc/gsv_"+str(count)+".jpg"
    count += 1
    image2 = "drive/MyDrive/Colab Notebooks/test_image_data_nc/gsv_"+str(count)+".jpg"
    count += 1
    image3 = "drive/MyDrive/Colab Notebooks/test_image_data_nc/gsv_"+str(count)+".jpg"
    count += 1
    image4 = "drive/MyDrive/Colab Notebooks/test_image_data_nc/gsv_"+str(count)+".jpg"
    count += 1

    try:
      img1 = Image.open(image1)
      img2 = Image.open(image2)
      img3 = Image.open(image3)
      img4 = Image.open(image4)
      # 이미지 4개를 전부 오픈한다.
      # 구글 API 특성상, Access에 실패하는 등의 문제가 생기면 데이터 중 일부가 유실되기도 하는데, 
      # 이 때에는 4개의 온전한 데이터로 이루어진 사진이 나오지 않으므로 try문을 벗어난다.
        
      new_img = Image.new("RGB", (1280, 1280))
      new_img.paste(img1, (0, 0))
      new_img.paste(img2, (640, 0))
      new_img.paste(img3, (0, 640))
      new_img.paste(img4, (640, 640))
      resize_img = new_img.resize((640, 640)) # 데이터 전처리 - 리사이징 작업
      
      resize_img.save("/content/drive/MyDrive/Colab Notebooks/final_noncrime/final"+str(finalcount)+".png", "png")
      # 리사이징되고 4개로 맞붙은 이미지를 저장한다. 
      print("final"+str(finalcount)+".png - "+"완료")
      finalcount += 1
      
    except:
      print("final"+str(finalcount)+".png - "+"실패")
      continue

from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications import vgg16
from IPython.display import display # 이미지 출력 함수
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense
from keras.models import Model
from keras import models
from keras import layers
from keras import optimizers
import keras.backend as K

# 추론하는 함수 predict_vgg16

def predict_vgg16(model, filename) :

  # 이미지 파일을 읽고 화면에 표시
  image = load_img(filename)
  # image = PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=688x550
  display(image)

  ## 파일 안 띄우고 싶으면 굳이? 안 해도 됨

  
  # 모델 사이즈로 이미지 파일을 읽기
  image = load_img(filename, target_size=(224, 224))
  
  # 이미지 데이터를 numpy로 변환
  image = img_to_array(image)

  # vgg16.preprocess_input()을 호출하기 위해 차원을 조정
  image = image.reshape((1, 224, 224, 3))

  # VGG16 모델 호출을 위해 데이터 전처리.
  # -255 ~ 255 사이 값으로 정규화한다.
  # 그리고 RGB를 BGR순으로 바꾼다.
  image = vgg16.preprocess_input(image)
  
  # 이미지를 모델에 적용
  yhat = model.predict(image)
  # yhat = [[2.03485320e-06 4.21382174e-06 1.45730738e-07 1.04057870e-06
  #          6.61934010e-08 2.63145339e-04 4.49358195e-05 2.03222541e-08
  #          ... ]] # 1000개 클래스에 대한 결과값.
  #
    
  # 모델 적용된 결과를 파싱
  label = vgg16.decode_predictions(yhat)
  # label = [[('n02655020', 'puffer', 0.9612253), ... ]]

  # 가장 확률이 높은 결과를 획득
  label = label[0][0]
  # label = ('n02655020', 'puffer', 0.9612253)

  # 라벨과 라벨을 예측한 확률을 출력
  print('%s (%.2f%%)' % (label[1], label[2]*100))

# 이미지 전처리

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = "train"
test_dir = "test"

#labeling data: imagedatagenerator을 사용하면 폴더 이름을 레이블링
#data augment

train_dir = "/content/drive/MyDrive/인지개_코딥/crime_data_2/train"
validation_dir = "/content/drive/MyDrive/인지개_코딥/crime_data_2/validation"
test_dir = "/content/drive/MyDrive/Colab Notebooks/test2"

batch_size = 128
image_size = 224

# 학습에 사용될 이미지 데이터 생성기
train_datagen = ImageDataGenerator(
      rotation_range=180, # 회전 최대 20도
      width_shift_range=0.2, # 좌우 이동
      height_shift_range=0.2, # 상하 이동
      horizontal_flip=True, # 좌우 반전
      vertical_flip=True, # 상하 반전
      )
 
# 검증에 사용될 이미지 데이터 생성기
validation_datagen = ImageDataGenerator()

test_datagen = ImageDataGenerator()

# 학습에 사용될 데이터 생성기  
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_size, image_size),
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=True)

# 검증에 사용될 데이터 생성기
validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(image_size, image_size),
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False)

test_generator = test_datagen.flow_from_directory(test_dir,
                                             target_size=(image_size, image_size),
                                             batch_size=batch_size,
                                             class_mode='categorical',
                                             shuffle=False)

class_num=len(train_generator.class_indices)
custom_labels = list(validation_generator.class_indices.keys())

# vgg16 불러오기

from tensorflow.keras.applications import vgg16
model = vgg16.VGG16()
model.summary()
files = [
         '/content/drive/MyDrive/Colab Notebooks/crime_data/train/crime/final6554.png',
         '/content/drive/MyDrive/Colab Notebooks/crime_data/train/crime/final6557.png',
]

K.clear_session() # 새로운 세션으로 시작

from tensorflow.keras.applications import VGG16
# 모델 불러오기
conv_layers = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))
conv_layers.summary()

# Convolution Layer를 학습되지 않도록 고정(Freezing)
for layer in conv_layers.layers:
    layer.trainable = False


# 새로운 모델 생성하기
model = models.Sequential()

# VGG16모델의 Convolution Layer를 추가
model.add(conv_layers)
 
# 모델의 Fully Connected 부분을 재구성
model.add(layers.Flatten())
model.add(layers.Dense(1024, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(class_num, activation='softmax'))

# 모델
model.summary()

vgg16_model_path = 'new_trained_from_vgg16.h5'

model.save(vgg16_model_path)

# 과적합 방지
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint
es = EarlyStopping(monitor='val_loss', mode='min', patience = 100, verbose = 1)
mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)

from keras.models import load_model
from tensorflow.keras import optimizers
import numpy as np

# 모델 로딩
model = load_model(vgg16_model_path)

# 모델 컴파일
model.compile(loss='binary_crossentropy',
              optimizer=optimizers.Adam(lr=1e-4),
              metrics=['acc'])


# 모델 학습
history = model.fit_generator(
      train_generator,
      steps_per_epoch=train_generator.samples//train_generator.batch_size ,
      epochs=5,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples//validation_generator.batch_size,
      callbacks = [es, mc],
      verbose=1)
 

# 모델 저장
model.save(vgg16_model_path)

from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score

# 모델 로딩
vgg16_model_path = '/content/drive/MyDrive/Colab Notebooks/new_trained_from_vgg16.h5'
model = load_model(vgg16_model_path)

true_classes = test_generator.classes
class_indices = train_generator.class_indices
class_indices = dict((v,k) for k,v in class_indices.items())

vgg_preds_ft = model.predict(test_generator)
vgg_pred_classes_ft = np.argmax(vgg_preds_ft, axis=1)

vgg_acc_ft = accuracy_score(true_classes, vgg_pred_classes_ft)
print("VGG16 Model Accuracy with Fine-Tuning: {:.2f}%".format(vgg_acc_ft * 100))